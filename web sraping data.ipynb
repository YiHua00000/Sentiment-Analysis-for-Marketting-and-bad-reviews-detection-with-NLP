{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page:1\n",
      "10\n",
      "Getting page:2\n",
      "20\n",
      "Getting page:3\n",
      "37\n",
      "Getting page:4\n",
      "47\n",
      "Getting page:5\n",
      "57\n",
      "Getting page:6\n",
      "67\n",
      "Getting page:7\n",
      "77\n",
      "Getting page:8\n",
      "88\n",
      "Getting page:9\n",
      "98\n",
      "Getting page:10\n",
      "108\n",
      "Getting page:11\n",
      "118\n",
      "Getting page:12\n",
      "128\n",
      "Getting page:13\n",
      "138\n",
      "Getting page:14\n",
      "149\n",
      "Getting page:15\n",
      "159\n",
      "Getting page:16\n",
      "169\n",
      "Getting page:17\n",
      "179\n",
      "Getting page:18\n",
      "189\n",
      "Getting page:19\n",
      "199\n",
      "Getting page:20\n",
      "209\n",
      "Getting page:21\n",
      "220\n",
      "Getting page:22\n",
      "230\n",
      "Getting page:23\n",
      "240\n",
      "Getting page:24\n",
      "250\n",
      "Getting page:25\n",
      "260\n",
      "Getting page:26\n",
      "270\n",
      "Getting page:27\n",
      "280\n",
      "Getting page:28\n",
      "290\n",
      "Getting page:29\n",
      "300\n",
      "Getting page:30\n",
      "310\n",
      "Getting page:31\n",
      "321\n",
      "Getting page:32\n",
      "331\n",
      "Getting page:33\n",
      "341\n",
      "Getting page:34\n",
      "352\n",
      "Getting page:35\n",
      "363\n",
      "Getting page:36\n",
      "373\n",
      "Getting page:37\n",
      "383\n",
      "Getting page:38\n",
      "395\n",
      "Getting page:39\n",
      "405\n",
      "Getting page:40\n",
      "415\n",
      "Getting page:41\n",
      "425\n",
      "Getting page:42\n",
      "435\n",
      "Getting page:43\n",
      "445\n",
      "Getting page:44\n",
      "455\n",
      "Getting page:45\n",
      "465\n",
      "Getting page:46\n",
      "475\n",
      "Getting page:47\n",
      "486\n",
      "Getting page:48\n",
      "496\n",
      "Getting page:49\n",
      "506\n",
      "Getting page:50\n",
      "516\n",
      "Getting page:51\n",
      "526\n",
      "Getting page:52\n",
      "537\n",
      "Getting page:53\n",
      "547\n",
      "Getting page:54\n",
      "557\n",
      "Getting page:55\n",
      "567\n",
      "Getting page:56\n",
      "577\n",
      "Getting page:57\n",
      "587\n",
      "Getting page:58\n",
      "597\n",
      "Getting page:59\n",
      "607\n",
      "Getting page:60\n",
      "622\n",
      "Getting page:61\n",
      "632\n",
      "Getting page:62\n",
      "643\n",
      "Getting page:63\n",
      "653\n",
      "Getting page:64\n",
      "663\n",
      "Getting page:65\n",
      "673\n",
      "Getting page:66\n",
      "683\n",
      "Getting page:67\n",
      "693\n",
      "Getting page:68\n",
      "703\n",
      "Getting page:69\n",
      "714\n",
      "Getting page:70\n",
      "724\n",
      "Getting page:71\n",
      "734\n",
      "Getting page:72\n",
      "742\n",
      "Getting page:73\n",
      "742\n",
      "Getting page:74\n",
      "742\n",
      "Getting page:75\n",
      "742\n",
      "Getting page:76\n",
      "742\n",
      "Getting page:77\n",
      "742\n",
      "Getting page:78\n",
      "742\n",
      "Getting page:79\n",
      "742\n",
      "Getting page:80\n",
      "742\n",
      "Getting page:81\n",
      "742\n",
      "Getting page:82\n",
      "742\n",
      "Getting page:83\n",
      "742\n",
      "Getting page:84\n",
      "742\n",
      "Getting page:85\n",
      "742\n",
      "Getting page:86\n",
      "742\n"
     ]
    }
   ],
   "source": [
    "\n",
    "review_list=[]\n",
    "def get_soup(url):\n",
    "    r=requests.get('http://localhost:8050/render.html', params={'url': url, 'wait': 2})\n",
    "    soup=BeautifulSoup(r.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "def get_reviews(soup):\n",
    "    reviews=soup.find_all('div', {'data-hook':'review'})\n",
    "    try:\n",
    "        for comments in reviews:\n",
    "            review={\n",
    "            'prodect':soup.title.text.replace('Amazon.com: Customer reviews:','').strip(),\n",
    "            'title':comments.find('a', {'data-hook':'review-title'}).text.strip(),\n",
    "            'rating':float(comments.find('i', {'data-hook':'review-star-rating'}).text.replace(\"out of 5 stars\", \" \").strip()),\n",
    "            'country':comments.find('span', {'data-hook':'review-date'}).text.split('on')[0].replace(\"Reviewed in the\", \" \").strip(),\n",
    "            'date':str(datetime.strptime(comments.find('span', {'data-hook':'review-date'}).text.split('on')[1].strip().replace(',', ''), '%B %d %Y')).split(\" \")[0],\n",
    "            'body':comments.find('span', {'data-hook':'review-body'}).text.strip(),\n",
    "            'help_people':int(comments.find('span', {'data-hook':'helpful-vote-statement'}).text.split(' ')[0].replace(',','')),\n",
    "            }\n",
    "            review_list.append(review)\n",
    "    except:\n",
    "        try:\n",
    "            for comments in reviews:\n",
    "                review={\n",
    "                'prodect':soup.title.text.replace('Amazon.com:','').strip(),\n",
    "                'title':comments.find('a', {'data-hook':'review-title'}).text.strip(),\n",
    "                'rating':float(comments.find('i', {'data-hook':'review-star-rating'}).text.replace(\"out of 5 stars\", \" \").strip()),\n",
    "                'country':comments.find('span', {'data-hook':'review-date'}).text.split('on')[0].replace(\"Reviewed in the\", \" \").strip(),\n",
    "                'date':str(datetime.strptime(comments.find('span', {'data-hook':'review-date'}).text.split('on')[1].strip().replace(',', ''), '%B %d %Y')).split(\" \")[0],\n",
    "                'body':comments.find('span', {'data-hook':'review-body'}).text.strip(),\n",
    "                'help_people':int(0),\n",
    "                }\n",
    "                review_list.append(review)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "\n",
    "for i in range(1,999):  \n",
    "    soup=get_soup(f'https://www.amazon.com/REDTIGER-Display-Dashboard-Recorder-Support/product-reviews/B08TT1RRGP/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber={i}')\n",
    "    print(f\"Getting page:{i}\")\n",
    "    get_reviews(soup)\n",
    "    print(len(review_list))\n",
    "    if not soup.find('li', {'class':'a-disabled a-last'}):\n",
    "        pass\n",
    "    else:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_data=pd.DataFrame(review_list)\n",
    "comment_data.to_csv('Amazon_review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
